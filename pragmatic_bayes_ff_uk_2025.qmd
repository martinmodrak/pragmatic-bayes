---
title: "Pragmatic Bayes"
format: 
  revealjs:
    theme: [default, custom.scss]
    incremental: true
    slide-number: true
author: Martin Modrák
date: 2025-10-16
---

# What is this about? {background-color="black" background-image=img/Night-sky-milky-way-galaxy-astrophotography_-_West_Virginia_-_ForestWander.jpg}


<!--
Notes to improve next time:
Frequentist calibration example - it has Bayesian methods, but shows freq calibration
"one coherent approach" not emphasized enough
Didn't really mention on philosophical commitments to nature of probability
More emphasize that I want to solve problems - typically estimation problems
-->

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
theme_set(theme_minimal(base_size = 20))
cache_dir <- "sim_cache"
```


:::{.image-source}
Modified from <a href="https://commons.wikimedia.org/wiki/File:Night-sky-milky-way-galaxy-astrophotography_-_West_Virginia_-_ForestWander.jpg">http://www.ForestWander.com</a>, <a href="https://creativecommons.org/licenses/by-sa/3.0/us/deed.en">CC BY-SA 3.0 US</a>, via Wikimedia Commons,
https://mc-stan.org/bayesplot/
:::


## I don’t want to convert you {background-color="black" background-image=img/convert_bayes.jpg}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Jehovah%27s_Witnesses_outside_the_British_Museum_02.jpg">Philafrenzy</a>, <a href="https://creativecommons.org/licenses/by-nc/4.0">CC-BY-NC 4.0:</a>, by 
:::

## What is Bayesian statistics?

Coin toss example

:::{.fragment}
### Using probability distributions to express uncertainty
:::

:::{.fragment}
### A coherent framework for updating beliefs
:::

## The Bayes rule

![](img/bayes_experimentology.png)

:::{.image-source}
<a href="https://lrissman03.github.io/experimentology/005-estimation.html">Philafrenzy</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>, Michael C. Frank, Mika Braginsky 
:::

:::{.notes}
Bayes rule alone does not make you a Bayesian!
:::

## Extracting information from a distribution

All relevant information is in [_expectations_]{.highlight1} and [_quantiles_]{.highlight2}

Can be derived analytically (rarely) 

... or approximated by averages, if we have access
to draws from the distribution.


## Using draws to understand a distribution

Assume $X \sim N(2, 2)$ what is the mean of $X^3$? 

:::{.fragment}
```{r}
#| echo: true
draws <- rnorm(1e6, 2, 2)
mean(draws^3)
```
:::

:::{.fragment}
What is the 95% interval?

```{r}
#| echo: true
quantile(draws^3, c(0.025, 0.975))
```
:::

## Pragmatic Bayes: a collection of ideas

:::{.fragment}
### Contrast with full _Bayesian epistemology_
:::
:::{.fragment}
No shaming our subjective/objective Bayesian friends!
:::
:::{.fragment}

Epistemology / philsci is not solved
:::
:::{.fragment}

### Can we do Bayesian [_statistics_]{.highlight1} without committing to Bayesian [_philosophy_]{.highlight2}?
:::

:::{.notes}
You can like some and reject other ideas
:::

## Main Influences

Deborah Mayo

Andrew Gelman

Stan community more broadly

Berna Devezer

Danielle J. Navarro

:::{.notes}
Mayo : severe testing

Gelman : Theoretical stastic is the theory of applied statistics

Stan : solve problems

Devezer : pluralism, rigour

Navarro : hypothesis testing

And many others
:::

# Pragmatic Bayesian aligns inferences with scientific questions {background-color="black" background-image=img/Custom_Made_Globes.jpg}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Cartographic_Publishing_-_Custom_Made_Globes_(NBY_5792).jpg">Bergin, Jerry</a>, Public domain, via Wikimedia Commons
:::

## Rich models 

- Varying scale between groups already difficult in freq

- Linear Ballistic Accumulator

- hidden Markov models

- Simulation-based inference


## Rich inferences

Inferences on derived quantities, prediction intervals?

- Just compute per sample! 

- Some questions don’t have freq answers without regularization (e.g. mean of general distribution). 
  - Once you regularize, you may as well do Bayes.

:::{.notes}
Inference on linear combinations of parameters is already annoying in freq.

Building freq prediction intervals with finite-sample guarantees is hard!
:::

# Pragmatic Bayesian tests their assumptions {background-color="black" background-image=img/Test.jpeg}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Test_(student_assessment).jpeg">KF</a>, Public domain, via Wikimedia Commons
:::

## Which assumptions?

### All of them

- Prior
- Likelihood
- Computation
- [Bayesian workflow](https://arxiv.org/abs/2011.01808)

:::{.notes}
Defensible prior often easy to find

One coherent approach!

Assumptions can be tested also in freq, but less obviously.
:::

## Modern Bayesian computation succeeds or fails loudly {.single-point}

:::{.notes}
Note how the freq NB GLMs fail, but give no warning
:::




# A bit more theory {background-image=img/Triang-cyl-sph4.svg.png background-color="black"}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Triang-cyl-sph4.svg">Ag2gaeh</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>, via Wikimedia Commons
:::

## Frequentist calibration

#### (continuous parameter)

- Confidence interval: 
  - For [any fixed]{.highlight1} parameter value, $x\%$ CI contains the true value [at least]{.highlight2} $x\%$ of the time.
  - Worst case
  - Usually conservative approximation

:::{.notes}
Replacing the inequality with strict equality would make the interval not exist in many cases.

Generalizes to confidence sets.
:::

## Bayesian calibration

#### (continuous parameter)

- Credible interval
  - [Averaged]{.highlight1} over the prior, $x\%$ CrI contains the true value [exactly]{.highlight2} $x\%$ of the time.
  - Specific values may lead to low coverage
  - Usually exact*

:::{.notes}
Typically MCMC, so not "exact computation", but we get an imprecise value for the "exact bound"

For discrete parameters need to convert to probability statements
:::

## Frequentist calibration example

$$
y \sim \text{Binomial}(20, \theta)
$$

:::{.fragment}
```{r binomial-prop}
source("binomial_proportion_coverage.R")
```
:::


## Bayes vs. freq comparison

Get the code!

Negative binomial regression

- Seizure counts etc.
- A general model for count data

## Bayes vs. freq comparison II

Fitting a negative binomial model, with 4 observations per group:

Frequentist via `MASS` package:

```r
MASS::glm.nb(y ~ group, data = data)
```

Bayesian with flat prior via `rstanarm` package:

```r
rstanarm::stan_glm.nb(y ~ group, data = data, 
  prior = NULL, prior_intercept = NULL)
```

## Frequentist tools don't attain correct coverage of CIs

```{r bayes-freq}
coverage_cache_file <- file.path(cache_dir, "nb_coverage_ff_uk.rds")
if(!file.exists(coverage_cache_file)) {
  source("nb_coverage_ff_uk.R")
} 

nb_coverage_df <- readRDS(coverage_cache_file)

nb_coverage_df |> 
  filter(!is.na(ci_low), !is.na(ci_high)) |> 
  mutate(covered = b >= ci_low & b <= ci_high) |> 
  group_by(method, b, phi) |> 
  summarise(coverage = mean(covered),
            n_covered = sum(covered),
            coverage_low = qbeta(0.025, n_covered, n() - n_covered + 1),
            coverage_high = qbeta(0.975, n_covered + 1 , n() - n_covered ),
            .groups = "drop"
  ) |> 
  ggplot()  + aes(x = b, ymin = coverage_low, y = coverage, ymax = coverage_high) +
  geom_hline(color = "orangered", yintercept = 0.95) +
  geom_ribbon(fill = "#888", alpha = 0.3) +
  geom_line() + facet_grid(method~phi, labeller = "label_both") + 
  scale_x_continuous("True fold change") + theme(strip.text.y = element_text(size = 10))
```


:::{.notes}
Bayesin 95% credible intervals (via brms/rstarm) provide good frequentist properties where
freq tools do not.

“The frequentist theory of Bayesian statistics” https://staff.science.uva.nl/b.j.k.kleijn/bkleijn-book-work-in-progress-Sep2022.pdf
https://www.jstor.org/stable/pdf/27028770.pdf (dense paper version)
:::


# Pragmatic Bayesian can outfreq the freq {background-image=img/tail_probs.jpg}

:::{.image-source}
Modified from <a href="https://commons.wikimedia.org/wiki/File:Null-hypothesis-region-eng.png">Smahdavi4</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>, via Wikimedia Commons
:::

## Bayes approximates freq

:::{.fragment}
### [Bernstein-von Mises](https://en.wikipedia.org/wiki/Bernstein%E2%80%93von_Mises_theorem)
:::
:::{.fragment}

We do not live in asymptotic utopia
:::

## Most freq methods are approximations!

- ML + Normal approximation
- ML + profile likelihood 
  - $\chi^2$ asymptotics of the likelihood-ratio test
  - Computationally expensive! 
  
:::{.notes}
Prove that CLT holds

They are valid only in the asymptotic utopia

For profile likelihood, finding a single confidence bound is slightly more costly than fitting the model

Bonus for penalized: problems at boundary values
:::


## It is hard to be a frequentist! 

### (with [exact]{.highlight1} [finite-sample]{.highlight2} guarantees)

- Exact freq computation is _very hard_
- Freq properties hard to empirically check
- Bayesian computation can be verified empirically ([SBC](https://doi.org/10.1214/23-BA1404), [Yao et al.](https://arxiv.org/abs/2305.14593))

:::{.notes}
Freq. properties cannot be exhaustively checked empirically
Bayesian computation can be (SBC + Yao approach)

If we both do Laplace approximations, is there any difference?

checking lme4 results with rstanarm
:::



# Pragmatic Bayesian understands Bayesian limits {background-color="black" background-image=img/Safety_Signs.JPG}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Safety_Signs.JPG">TeWeBs</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>, via Wikimedia Commons
:::

## Important problems

- Selection effects
- Early stopping


# Pragmatic Bayesian is not afraid of freq {background-color="black" background-image=img/Beyond_the_Dark_Angel_-_metal_band_photo.jpg}
:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Beyond_the_Dark_Angel_-_metal_band_photo.jpg">Lukáš Beneda</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>, via Wikimedia Commons
:::

## Some use cases of freq

- Sequential designs
- Freq as approximate Bayes
  - Flat prior + normal approximation
  - Can [check with SBC](https://hyunjimoon.github.io/SBC/articles/implementing_backends.html)

# Pragmatic Bayesian thinks about causality {background-color="black" background-image=img/Causal_assumptions_for_developing_bias-minimized_models_for_markers_of_imminent_myocardial_infarction.webp}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:Causal_assumptions_for_developing_bias-minimized_models_for_markers_of_imminent_myocardial_infarction.webp">Authors of the study: Stefan Gustafsson, Erik Lampa, Karin Jensevik Eriksson, Adam S. Butterworth, Sölve Elmståhl, Gunnar Engström, Kristian Hveem, Mattias Johansson, Arnulf Langhammer, Lars Lind, Kristi Läll, Giovanna Masala, Andres Metspalu, Conchi Moreno-Iribas, Peter M. Nilsson, Markus Perola, Birgit Simell, Hemmo Sipsma, Bjørn Olav Åsvold, Erik Ingelsson, Ulf Hammar, Andrea Ganna, Bodil Svennblad, Tove Fall &amp; Johan Sundström</a>, <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>, via Wikimedia Commons
:::

## Bayesian causality

- McElreath: [Full luxury Bayesian  inference](https://elevanth.org/blog/2021/06/29/regression-fire-and-dangerous-things-3-3/)

- Dawid: [Causal inference as decision theory](http://dx.doi.org/10.1515/jci-2020-0008)




# My personal non-reasons to use Bayes {background-color="black" background-image=img/West_Africa.jpg}

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:West_Africa_(2175061620).jpg">Steve Evans from Citizen of the World</a>, <a href="https://creativecommons.org/licenses/by/2.0">CC BY 2.0</a>, via Wikimedia Commons
:::

:::{.notes}
Philosophical arguments that I find not very practically useful.
:::

## Prior information 

No!

:::{.fragment}
We can rarely elicit and express precise enough priors
:::

## Sequential updating? 

No!

:::{.fragment}
In practice just fit a big model to all data.
:::


## Epistemology? 

No!

:::{.fragment}
Severity of tests matters.
:::

:::{.fragment}
Especially no to Bayes factors.
:::

# Why I use Bayesian tools {.lower background-color="black" background-image=img/EXCITE_2024.jpg} 

And maybe you should too?

:::{.image-source}
<a href="https://commons.wikimedia.org/wiki/File:EXCITE_2024-_Launch_and_Recovery_(SVS14726_-_5_-_EXCITE_Balloon_Inflates).jpg">NASA&#039;s Scientific Visualization Studio - Advocates in Manpower Management, Inc./Sophia Roberts, University of Maryland College Park/Jeanette Kazmierczak</a>, Public domain, via Wikimedia Commons
:::

## Pragmatic reasons

- Useful!
- One coherent approach!
- Finite sample guarantees!
- Rich models!

:::{.fragment}
### Thanks for your attention!

Slide & simulation sources:   
[https://github.com/martinmodrak/pragmatic-bayes](https://github.com/martinmodrak/pragmatic-bayes)

:::{.qrcode}
```{r qr, fig.width=3,fig.height=3}
plot(qrcode::qr_code("https://github.com/martinmodrak/pragmatic-bayes"))
```

:::

:::

